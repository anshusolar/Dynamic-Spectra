#!/usr/bin/env python
# coding: utf-8

import gzip
from astropy.io import fits
import numpy as np
import matplotlib.pyplot as plt
from glob import glob
from datetime import datetime, timedelta
from astropy.time import Time, TimeDelta
import matplotlib.dates as mdates
from matplotlib.dates import DateFormatter, MinuteLocator, date2num
from matplotlib.ticker import LogLocator, ScalarFormatter, NullFormatter
from scipy.interpolate import RegularGridInterpolator
import os

# --- ORFEES Functions ---
def preprocess_log_median(data, baseline_len=100):
    """Convert data to log10 scale and subtract median over initial baseline_len time steps."""
    data_clipped = np.clip(data, 1e-3, None)
    log_data = np.log10(data_clipped)
    median_baseline = np.median(log_data[:baseline_len, :], axis=0)
    normalized_data = log_data - median_baseline
    return normalized_data

def load_orfees_data(fits_file, t_start, t_end, f_min, f_max):
    """Load and process ORFEES Stokes I data with time and frequency zooming."""
    try:
        with fits.open(fits_file) as hdul:
            freq_hdu = hdul[1].data
            freqs = np.concatenate([
                freq_hdu['FREQ_B1'][0],
                freq_hdu['FREQ_B2'][0],
                freq_hdu['FREQ_B3'][0],
                freq_hdu['FREQ_B4'][0],
                freq_hdu['FREQ_B5'][0]
            ])
            spec_hdu = hdul[2].data
            data_i = np.hstack([
                spec_hdu['STOKESI_B1'],
                spec_hdu['STOKESI_B2'],
                spec_hdu['STOKESI_B3'],
                spec_hdu['STOKESI_B4'],
                spec_hdu['STOKESI_B5']
            ])
            start_time = Time('2024-05-29T12:00:00', format='isot', scale='utc')
            time_deltas = TimeDelta(np.arange(data_i.shape[0]) * 0.1, format='sec')
            times = start_time + time_deltas
            freq_indices = np.argsort(freqs)
            freqs_sorted = freqs[freq_indices]
            data_i_processed = preprocess_log_median(data_i)
            data_i_processed = data_i_processed[:, freq_indices]
            t_start = Time(t_start, format='isot')
            t_end = Time(t_end, format='isot')
            time_mask = (times >= t_start) & (times <= t_end)
            freq_mask = (freqs_sorted >= f_min) & (freqs_sorted <= f_max)
            times_zoom = times[time_mask]
            freqs_zoom = freqs_sorted[freq_mask]
            data_i_zoom = data_i_processed[time_mask][:, freq_mask]
            print(f"ORFEES: Data shape: {data_i_zoom.shape}, Times: {times_zoom.shape}, Freqs: {freqs_zoom.shape}")
            return times_zoom, freqs_zoom, data_i_zoom
    except Exception as e:
        print(f"Error processing ORFEES FITS file: {e}")
        return None, None, None

# --- CALLISTO Functions ---
def load_callisto_data(file):
    """Load CALLISTO FITS data."""
    with fits.open(file) as hdu:
        data = hdu[0].data.astype(np.float32)
        hdr = hdu[0].header
        t_start = hdr['CRVAL1']
        dt = hdr['CDELT1']
        nt = hdr['NAXIS1']
        time_sec = t_start + dt * np.arange(nt)
        date_str = hdr['DATE-OBS']
        base_time = datetime.strptime(date_str, "%Y/%m/%d")
        time_axis = np.array([base_time + timedelta(seconds=float(s)) for s in time_sec])
        freqs = hdu[1].data['Frequency'][0]
        return time_axis, freqs, data

def process_callisto_data(file_pattern, data_dir, t_start, t_end, f_min, f_max):
    """Combine and process CALLISTO data with zooming."""
    full_pattern = f"{data_dir}/{file_pattern}"
    files = sorted(glob(full_pattern))
    print(f"CALLISTO: Number of files: {len(files)}")
    if not files:
        print(f"No CALLISTO files found matching {full_pattern}")
        return None, None, None

    data_list = []
    time_list = []
    freqs = None
    for file in files:
        t, f, d = load_callisto_data(file)
        time_list.append(t)
        data_list.append(d)
        if freqs is None:
            freqs = f
        elif not np.allclose(freqs, f):
            print(f"Warning: Frequency mismatch in {file}")

    freq_flipped = np.flip(freqs)[6:]
    data_flipped = [np.flip(d, axis=0)[6:, :] for d in data_list]
    time_combined = np.concatenate(time_list)
    data_combined = np.hstack(data_flipped)

    time_num = mdates.date2num(time_combined)
    unique_times, unique_idx = np.unique(time_num, return_index=True)
    time_combined = time_combined[unique_idx]
    n_times = len(time_combined)
    data_aligned = np.full((len(freq_flipped), n_times), np.nan)
    idx = np.searchsorted(unique_times, time_num)
    valid = (idx < n_times) & (idx >= 0)
    idx = idx[valid]
    if idx.size != data_combined.shape[1]:
        print(f"Warning: CALLISTO time mismatch. Expected {data_combined.shape[1]}, got {idx.size}")
        idx = idx[:data_combined.shape[1]]
        data_combined = data_combined[:, :idx.size]
    data_aligned[:, idx] = data_combined

    median_spectrum = np.nanmedian(data_aligned, axis=1, keepdims=True)
    data_subtracted = data_aligned - median_spectrum

    t_start = Time(t_start, format='isot')
    t_end = Time(t_end, format='isot')
    time_astropy = Time(time_combined)
    time_mask = (time_astropy >= t_start) & (time_astropy <= t_end)
    freq_mask = (freq_flipped >= f_min) & (freq_flipped <= f_max)
    times_zoom = time_combined[time_mask]
    freqs_zoom = freq_flipped[freq_mask]
    data_zoom = data_subtracted[freq_mask, :][:, time_mask]
    print(f"CALLISTO: Data shape: {data_zoom.shape}, Times: {times_zoom.shape}, Freqs: {freqs_zoom.shape}")
    return times_zoom, freqs_zoom, data_zoom

# --- NDA Functions ---
def load_nda_data(fits_file, t_start, t_end, f_min, f_max):
    """Load and process NDA Stokes I data with zooming."""
    try:
        with fits.open(fits_file) as hdul:
            date_obs = hdul[0].header['DATE-OBS']
            try:
                date_obs_iso = datetime.strptime(date_obs, '%d/%m/%Y').strftime('%Y-%m-%dT00:00:00')
            except ValueError:
                date_obs_iso = '2024-05-29T00:00:00'
            data_i = hdul[1].data.T
            freqs = hdul[3].data['frequency_in_MHz']
            times = hdul[4].data['time_in_seconds']
            if data_i.shape[0] > len(times):
                data_i = data_i[:len(times), :]
            t0 = Time(date_obs_iso)
            times = t0 + TimeDelta(times, format='sec')
            data_clipped = np.clip(data_i, 1e-3, None)
            log_data = np.log10(data_clipped)
            log_data -= np.median(log_data[:100, :], axis=0)
            t_start = Time(t_start, format='isot')
            t_end = Time(t_end, format='isot')
            time_mask = (times >= t_start) & (times <= t_end)
            freq_mask = (freqs >= f_min) & (freqs <= f_max)
            times_zoom = times[time_mask]
            freqs_zoom = freqs[freq_mask]
            data_zoom = log_data[time_mask][:, freq_mask]
            print(f"NDA: Data shape: {data_zoom.shape}, Times: {times_zoom.shape}, Freqs: {freqs_zoom.shape}")
            return times_zoom, freqs_zoom, data_zoom
    except Exception as e:
        print(f"Error processing NDA FITS file: {e}")
        return None, None, None

# --- LOFAR Functions ---
def load_lofar_data(fits_file, t_start, t_end, f_min, f_max):
    """Load and process LOFAR Stokes I data with time and frequency zooming."""
    try:
        with fits.open(fits_file) as hdul:
            header = hdul[0].header
            data = hdul[0].data.astype(np.float32)
            if len(data.shape) != 2:
                raise ValueError("Expected 2D data array")
            date_obs = header.get('DATE-OBS', '2024/05/29')
            time_obs = header.get('TIME-OBS', '13:05:00.000000')
            t_ref = Time(f"{date_obs.replace('/', '-')[:10]}T{time_obs[:8]}", format='isot')
            table = hdul[1].data
            freqs = table[0][0]  # Frequencies in MHz
            n_times = data.shape[0]
            time_step = header.get('CDELT1', 0.25)  # Seconds
            times_sec = np.arange(n_times) * time_step
            times = t_ref + TimeDelta(times_sec, format='sec')
            data = data.T  # Transpose to (freqs, times)
            data_clipped = np.clip(data, 1e-3, None)
            log_data = np.log10(data_clipped)
            median_spectrum = np.nanmedian(log_data, axis=1, keepdims=True)
            data_processed = log_data - median_spectrum
            t_start = Time(t_start, format='isot')
            t_end = Time(t_end, format='isot')
            time_mask = (times >= t_start) & (times <= t_end)
            freq_mask = (freqs >= f_min) & (freqs <= f_max)
            times_zoom = times[time_mask]
            freqs_zoom = freqs[freq_mask]
            data_zoom = data_processed[freq_mask, :][:, time_mask]
            #print(f"LOFAR: Data shape: {data_zoom.shape}, Times: {times_zoom.shape}, Freqs: {freqs_zoom.shape}")
            return times_zoom, freqs_zoom, data_zoom
    except Exception as e:
        print(f"Error processing LOFAR FITS file {fits_file}: {e}")
        return None, None, None

def process_lofar_data(lofar_files, t_start, t_end, f_min, f_max):
    """Process multiple LOFAR files and combine them."""
    all_times = []
    all_data = []
    freqs = None
    for file in lofar_files:
        times, freqs_file, data = load_lofar_data(file, t_start, t_end, f_min, f_max)
        if times is not None:
            all_times.append(times)
            all_data.append(data)
            if freqs is None:
                freqs = freqs_file
            elif not np.allclose(freqs, freqs_file):
                print(f"Warning: Frequency mismatch in {file}")
    if all_times:
        combined_times = np.concatenate([t.datetime for t in all_times])
        combined_times = Time(combined_times, format='datetime')
        combined_data = np.concatenate(all_data, axis=1)  # Concatenate along time axis
        print(f"LOFAR combined: Data shape: {combined_data.shape}, Times: {combined_times.shape}, Freqs: {freqs.shape}")
        return combined_times, freqs, combined_data
    else:
        return None, None, None

# --- Combined Data Processing ---
def combine_data(orfees_data, callisto_data, nda_data, lofar_data, time_range, f_min_total, f_max_total):
    """Combine data from ORFEES, CALLISTO, NDA, and LOFAR into a single array."""
    t_start, t_end = Time(time_range[0], format='isot'), Time(time_range[1], format='isot')
    n_times = int((t_end - t_start).to_value('sec') / 0.1) + 1
    time_grid = t_start + TimeDelta(np.arange(n_times) * 0.1, format='sec')
    time_grid_mpl = date2num(time_grid.datetime)
    time_edges = np.concatenate([time_grid_mpl, [time_grid_mpl[-1] + (time_grid_mpl[-1] - time_grid_mpl[-2])]])

    freqs_all = []
    if orfees_data[0] is not None:
        freqs_all.append(orfees_data[1])
    if callisto_data[0] is not None:
        freqs_all.append(callisto_data[1])
    if nda_data[0] is not None:
        freqs_all.append(nda_data[1])
    if lofar_data[0] is not None:
        freqs_all.append(lofar_data[1])
    if not freqs_all:
        raise ValueError("No valid frequency data available")
    
    freqs_combined = np.unique(np.concatenate(freqs_all))
    freqs_combined = freqs_combined[(freqs_combined >= f_min_total) & (freqs_combined <= f_max_total)]
    freq_edges = np.concatenate([freqs_combined, [freqs_combined[-1] + (freqs_combined[-1] - freqs_combined[-2])]])

    data_combined = np.full((n_times, len(freqs_combined)), np.nan)

    def interpolate_data(times, freqs, data, time_grid, freqs_combined):
        if times is None or len(times) < 2 or len(freqs) < 2:
            return np.full((len(time_grid), len(freqs_combined)), np.nan)
        time_num = date2num(times.datetime if isinstance(times, Time) else times)
        data_norm = (data - np.nanmean(data)) / np.nanstd(data) if np.nanstd(data) != 0 else data
        points = (time_num, freqs)
        values = data_norm
        interpolator = RegularGridInterpolator(points, values, method='linear', bounds_error=False, fill_value=np.nan)
        time_grid_mpl = date2num(time_grid.datetime)
        time_mesh, freq_mesh = np.meshgrid(time_grid_mpl, freqs_combined, indexing='ij')
        interp_points = np.vstack([time_mesh.ravel(), freq_mesh.ravel()]).T
        data_interp = interpolator(interp_points).reshape(len(time_grid), len(freqs_combined))
        return data_interp

    if orfees_data[0] is not None:
        data_orfees = interpolate_data(orfees_data[0], orfees_data[1], orfees_data[2], time_grid, freqs_combined)
        mask = (freqs_combined >= orfees_data[1].min()) & (freqs_combined <= orfees_data[1].max())
        data_combined[:, mask] = data_orfees[:, mask]

    if callisto_data[0] is not None:
        data_callisto = interpolate_data(callisto_data[0], callisto_data[1], callisto_data[2].T, time_grid, freqs_combined)
        mask = (freqs_combined >= callisto_data[1].min()) & (freqs_combined <= callisto_data[1].max())
        data_combined[:, mask] = data_callisto[:, mask]

    if lofar_data[0] is not None:
        data_lofar = interpolate_data(lofar_data[0], lofar_data[1], lofar_data[2].T, time_grid, freqs_combined)
        mask = (freqs_combined >= lofar_data[1].min()) & (freqs_combined <= lofar_data[1].max())
        data_combined[:, mask] = data_lofar[:, mask]

    if nda_data[0] is not None:
        data_nda = interpolate_data(nda_data[0], nda_data[1], nda_data[2], time_grid, freqs_combined)
        mask = (freqs_combined >= nda_data[1].min()) & (freqs_combined <= nda_data[1].max())
        data_combined[:, mask] = data_nda[:, mask]

    return time_grid, freqs_combined, data_combined

# --- Plotting ---
def plot_combined_spectrum(time_grid, freqs, data, time_range, title):
    """Plot a single dynamic spectrum."""
    fig, ax = plt.subplots(figsize=(12, 8))
    time_edges = date2num(time_grid.datetime)
    time_edges = np.concatenate([time_edges, [time_edges[-1] + (time_edges[-1] - time_edges[-2])]])
    freq_edges = np.concatenate([freqs, [freqs[-1] + (freqs[-1] - freqs[-2])]])
    vmin, vmax = np.nanpercentile(data, [10, 95])  # Normalize for visibility
    mesh = ax.pcolormesh(time_edges, freq_edges, data.T, cmap='viridis', vmin=vmin, vmax=vmax, shading='auto')
    ax.set_yscale('log')
    ax.yaxis.set_major_locator(LogLocator(base=10.0, subs=[1.0, 2.0, 5.0], numticks=15))
    ax.yaxis.set_major_formatter(ScalarFormatter())
    ax.yaxis.set_minor_formatter(NullFormatter())
    ax.set_xlabel('Time (UT, 2024-05-29)')
    ax.set_ylabel('Frequency (MHz)')
    ax.set_title(title)
    ax.xaxis.set_major_formatter(DateFormatter('%H:%M:%S'))
    ax.xaxis.set_major_locator(MinuteLocator(interval=5))
    ax.xaxis.set_minor_locator(MinuteLocator(interval=5))
    t_start, t_end = Time(time_range[0], format='isot'), Time(time_range[1], format='isot')
    ax.set_xlim(date2num(t_start.datetime), date2num(t_end.datetime))
    ax.set_ylim(freqs.min(), freqs.max())
    fig.autofmt_xdate()
    plt.tight_layout()
    plt.savefig('combined_dynamic_spectrum_with_lofar.png', dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

# --- Main Execution ---
orfees_file = 'int_orf20240529_120000_0.1.fts'
callisto_dir = 'EGYPT-Alexandria_20240529'
callisto_pattern = 'EGYPT-Alexandria_*_02.fit.gz'
nda_file = 'NDA_29052024_1_12_00_00_15_35_57.fits'
lofar_dir = 'lofar_fits_files'
lofar_pattern = 'LOFAR_20240529_*_LBA_OUTER_S0.fits'

time_range = ('2024-05-29T14:20:00', '2024-05-29T15:30:00')
f_min_total, f_max_total = 15, 700  # Combined frequency range

# Load data
nda_data = load_nda_data(nda_file, time_range[0], time_range[1], f_min=15, f_max=25)
lofar_files = sorted(glob(os.path.join(lofar_dir, lofar_pattern)))
lofar_data = process_lofar_data(lofar_files, time_range[0], time_range[1], f_min=25, f_max=85)
callisto_data = process_callisto_data(callisto_pattern, callisto_dir, time_range[0], time_range[1], f_min=85, f_max=144)
orfees_data = load_orfees_data(orfees_file, time_range[0], time_range[1], f_min=144, f_max=700)




# Combine and plot
time_grid, freqs_combined, data_combined = combine_data(orfees_data, callisto_data, nda_data, lofar_data, time_range, f_min_total, f_max_total)
plot_combined_spectrum(time_grid, freqs_combined, data_combined, time_range, 
                      'Combined Dynamic Spectrum (ORFEES, CALLISTO, NDA, LOFAR) - 2024-05-29')
